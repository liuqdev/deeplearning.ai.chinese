{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy基本操作\n",
    "\n",
    "欢迎来到你的第一个深度学习专业(可选)编程训练。这个任务中你将学到：\n",
    "\n",
    "- 学会如何使用numpy.\n",
    "\n",
    "- 动手实现一些基础和兴的深度学习函数，例如softmax, sigmoid, dsigmoid等\n",
    "\n",
    "- 学会如何处理数据，比如正则化输入和重设输入图像大小.\n",
    "\n",
    "- 意识到向量化的重要性.\n",
    "\n",
    "- 理解Python的广播机制是如何运行的.\n",
    "\n",
    "以上就是为你进行准备的任务.花费一些功夫来完成并且确保通过训练来得到理想的输出结果. 在一些编程块中,你会发现\"#一系列函数: 函数名称\"的备注,请不要修改.在你完成练习后，提交你的工作并检验结果。正确率达到70%以上就算作通过.祝你好运.:-)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python的numpy基础操作 v3版本 (可选的练习)\n",
    "\n",
    "\n",
    "欢迎来到你的第一个任务.假如你之前从未使用过python的话，通过这个练习你将对python有一个初读的映象，并且还会帮助你熟悉你所需要的函数.\n",
    "\n",
    "**说明:**\n",
    "- 本练习使用的是Python3\n",
    "- 除非明确地指出要使用到for循环或者while循环，否则尽量不要使用\n",
    "- 不要修改在某些小单元中的(# GRADED FUNCTION [function name])注释.变更之后不保证能够正确地给你的程序判分,另外,每个这样的评论中至多写一个函数\n",
    "- 编写你自己的函数之后,运行你的程序,来验证自己的结果\n",
    "\n",
    "**通过本次练习你将:**\n",
    "- 能够使用iPython (Jupyter)Notebooks\n",
    "- 能够使用numpy函数和numpy内置的矩阵/向量操作符\n",
    "- 理解\"广播\"的机制\n",
    "- 能够编写向量化程序\n",
    "\n",
    "让我们开始吧！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 关于ipython (Jupyter) Notebooks\n",
    "\n",
    "Ipython (Jupyter) Notebooks是一款嵌入到浏览器当中的交互式编程环境.你将在这门课程中使用它.你只需要在### 代码开始 ### 和 ### 代码结束 ###注释中间来编写代码.写完你的代码之后,你可以按住`Shift`+`Enter`或者点击上方的`Run Cell(播放标志图案)`按钮来运行代码.\n",
    "\n",
    "当你看到\"(≈ X 行代码)\"的注释，表明此处大约需要编写多少行程序,实际可稍长或稍短.\n",
    "\n",
    "**Exercise**: 试着运行下面的示例，从`Hello World`开始."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 代码开始 ### (≈ 1 行代码)\n",
    "test = \"Hello World\"\n",
    "### 代码结束 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: Hello World\n"
     ]
    }
   ],
   "source": [
    "print (\"test: \"+ test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**期望输出**:\n",
    "test: Hello World"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "**这个示例旨在告诉我们**\n",
    "- 按住`SHIFT+ENTER`(或者点击上方的`Run Cell`)来运行\n",
    "- 使用Python3在特定位置写下你的代码\n",
    "- 不要修改特定区域之外的代码  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - 使用numpy来编写基本的函数 ##\n",
    "\n",
    "Numpy是Python中用于科学计算的主要几个包之一.在它背后有强大的而活跃的(www.numpy.org)社区在支持.在这个联系中，你会学到numpy中几个关键的函数，例如np.exp, np.log, 以及np.reshape. 你需要掌握这些函数的使用，因为在之后的练习中你还会用到它们.\n",
    "\n",
    "### 1.1 - sigmoid 函数， np.exp() ### \n",
    "\n",
    "在学会使用np.exp()之前，你会使用math.exp()来动手实现sigmoid函数.之后你就会理解为什么np.exp()性能比math.exp()要好.\n",
    "\n",
    "**练习**: 编写一个函数,返回一个实数的sigmoid值,其中的指数函数使用,math.exp().\n",
    "\n",
    "**回顾**:\n",
    "$sigmoid(x) = \\frac{1}{1+e^{-x}}$有时候也叫做logistic function(逻辑函数).它是一种典型的非线性函数,不仅应用于机器学习,同时也应用于深度学习中.\n",
    "\n",
    "<img src=\"images/Sigmoid.png\" style=\"width:500px;height:228px;\">\n",
    "\n",
    "当你引用一个特定的库中的函数时,要预先声明`package_name.function()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 函数: basic_sigmoid\n",
    "\n",
    "import math\n",
    "\n",
    "def basic_sigmoid(x):\n",
    "    \"\"\"\n",
    "    计算一个实数的sigmoid值\n",
    "    \n",
    "    参数:\n",
    "    x -- 一个标量\n",
    "    \n",
    "    返回:\n",
    "    s -- sigmoid(x)\n",
    "    \n",
    "    \"\"\"\n",
    "    ### 代码开始 ### (≈ 1 行代码)\n",
    "    s = 1.0/(1+math.exp(-x))\n",
    "    ### 代码结束 ###\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9525741268224334"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_sigmoid(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**期望输出**: \n",
    "<table style = \"width:40%\">\n",
    "    <tr>\n",
    "    <td>** basic_sigmoid(3) **</td> \n",
    "        <td>0.9525741268224334 </td> \n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实际上我们在深度学习中很少使用\"math\"库,因为其输入要保证是实数.在深度学习中我们使用矩阵以及向量,这就是为什么numpy更加实用了."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "bad operand type for unary -: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-457c6d5855eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mbasic_sigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 运行之后回出现一个错误,因为这里x是一个向量\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-0d59d93f9ecb>\u001b[0m in \u001b[0;36mbasic_sigmoid\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \"\"\"\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m### 代码开始 ### (≈ 1 行代码)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[1;31m### 代码结束 ###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: bad operand type for unary -: 'list'"
     ]
    }
   ],
   "source": [
    "### 在深度学习中,我们使用numpy来代替math中的原因之一 ###\n",
    "x = [1, 2, 3]\n",
    "print(type(x))\n",
    "basic_sigmoid(x) # 运行之后回出现一个错误,因为这里x是一个向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假如$ x=(x_1, x_2, ..., x_n)$是一个行向量, $np.exp(x)$会对x中每一个元素x求出其指数函数值.因此,输出结果会是:$np.exp(x) = (e^{x_1}, e^{x_2}, ..., e^{x_n})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2.71828183   7.3890561   20.08553692]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# np.exp 使用示例\n",
    "x = np.array([1, 2, 3])\n",
    "print(np.exp(x)) # 结果为 (exp(1)), exp(2), exp(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此外,假如x是一个向量,形如$s = x+3$或者$s = \\frac {1}{x}$会输出和输入x大小一致的结果向量."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 5 6]\n"
     ]
    }
   ],
   "source": [
    "# 向量操作示例\n",
    "x = np.array([1, 2, 3])\n",
    "print(x+3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在任何时候,对于numpy中的函数有疑问,都可以去其[官方文档](https://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.exp.html)中寻找答案.\n",
    "\n",
    "你也可以在notebook中的任何一个cell中编写如`np.exp?`来快速查看文档中有关的此内容.\n",
    "\n",
    "**练习**:使用numpy来实现sigmoid函数\n",
    "\n",
    "**回顾**:x 可以是一个实数,一个向量,或者一个矩阵.在numpy中我们使用numpy arrays 来表示这些数据结构.暂时不用深入了解.\n",
    "\n",
    "$$ \\text{For } x \\in \\mathbb{R}^n \\text{,     } sigmoid(x) = sigmoid\\begin{pmatrix}\n",
    "    x_1  \\\\\n",
    "    x_2  \\\\\n",
    "    ...  \\\\\n",
    "    x_n  \\\\\n",
    "\\end{pmatrix} = \\begin{pmatrix}\n",
    "    \\frac{1}{1+e^{-x_1}}  \\\\\n",
    "    \\frac{1}{1+e^{-x_2}}  \\\\\n",
    "    ...  \\\\\n",
    "    \\frac{1}{1+e^{-x_n}}  \\\\\n",
    "\\end{pmatrix}\\tag{1} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 函数: sigmoid\n",
    "\n",
    "import numpy as np # 书写这句话表示,你可以使用np.function() 代替 numpy.function()来使用numpy中的函数\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    计算x的sigmoid\n",
    "    \n",
    "    参数:\n",
    "    x -- 一个标量,或者任意大小的numpy array\n",
    "    \n",
    "    返回:\n",
    "    s -- sigmoid(x)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### 代码开始 ### (≈ 1 行代码)\n",
    "    s = 1.0/(1+np.exp(-x))\n",
    "    ### 代码结束 ###\n",
    "    \n",
    "    return s\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.73105858,  0.88079708,  0.95257413])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1, 2, 3])\n",
    "sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**期望输出**: \n",
    "<table>\n",
    "    <tr> \n",
    "        <td> **sigmoid([1,2,3])**</td> \n",
    "        <td> array([ 0.73105858,  0.88079708,  0.95257413]) </td> \n",
    "    </tr>\n",
    "</table> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 - Sigmoid 梯度\n",
    "\n",
    "我们需要使用后向传播(backpropagation),计算梯度来优化损失函数(loss functions).下面开始编写你的第一个梯度函数.\n",
    "\n",
    "**练习**:实现函数 sigmoid_grad() 来计算相对于其输入x的梯度.其梯度计算公式为$$sigmoid\\_derivative(x) = \\sigma'(x) = \\sigma(x)(1 - \\sigma(x))\\tag{2}$$\n",
    "\n",
    "编写这个函数通常需要两步:\n",
    "1. 设s为x的sigmoid, 你也许会发现sigmoid(x)函数十分有用.\n",
    "2. 计算$\\sigma'(x)=s(1-s)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 函数: sigmoid_derivative\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    \"\"\"\n",
    "    对于输入x计算其梯度(有时候也叫坡度或者导数).你可以将sigmoid函数的结果存储到变量中,然后使用其来计算梯度.\n",
    "    \n",
    "    参数:\n",
    "    x -- 一个标量或者numpy array\n",
    "    \n",
    "    返回:\n",
    "    ds -- 计算得到的梯度\n",
    "    \"\"\"\n",
    "    \n",
    "    ### 代码开始 ### (≈ 2 行代码)\n",
    "    s = 1/(1+np.exp(-x))\n",
    "    ds = s*(1-s)\n",
    "    ### 代码结束 ###\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid_derivative(x)= [ 0.19661193  0.10499359  0.04517666]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1, 2, 3])\n",
    "print(\"sigmoid_derivative(x)= \"+ str(sigmoid_derivative(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**期望输出**: \n",
    "\n",
    "\n",
    "<table>\n",
    "    <tr> \n",
    "        <td> **sigmoid_derivative([1,2,3])**</td> \n",
    "        <td> [ 0.19661193  0.10499359  0.04517666] </td> \n",
    "    </tr>\n",
    "</table> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 - 重塑array\n",
    "\n",
    "深度学习中经常用到两个函数 [np.shape](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.shape.html) 和 [np.reshape()](https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html). \n",
    "- X.shape 来获得一个矩阵或者向量X的形状大小(维度值)\n",
    "- X.reshape(...) 将X重塑为其他维度值\n",
    "\n",
    "举例子,在计算机科学中,一幅图像表示为一个三维 array,形状为$(length, height, depth = 3)$.但是当你将其作为一个算法的输入时,需要将其重塑为一个形状为$(length*height, 3)$的向量.换句话说,我们展开,或者说重塑了这张图像,将其从一个三维的array转换为一个一维的向量.\n",
    "\n",
    "<img src=\"images/image2vector_kiank.png\" style=\"width:500px;height:300;\">\n",
    "\n",
    "**练习**:实现`image2vector()`,输入参数形状为 (length, heigh, 3) 返回一个向量,形状为 (length\\*height\\*3, 1).\n",
    "1). 例如,如果你想把一个形状为(a, b, c)的array v转换为一个形状为(a*b, c)的向量.你可能这样:\n",
    "```python\n",
    "v = v.reshape((v.shape[0]*v.shape[1], v.shape[2])) # v.shape[0] = a ; v.shape[1] = b ; v.shape[2] = c\n",
    "```\n",
    "- 不要将图像的维度数定为常量且不能修改.可以使用`image.shape[0]`来查看你所需要的哪一维的大小.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 函数: image2vector\n",
    "def image2vector(image):\n",
    "    \"\"\"\n",
    "    参数:\n",
    "    image -- 形状为(length, height, depth)的numpy array\n",
    "    \n",
    "    返回:\n",
    "    v -- 形状为(length*height*depth, 1)的向量\n",
    "    \"\"\"\n",
    "    \n",
    "    ### 代码开始 ### (≈ 1 行代码)\n",
    "    v = image.reshape( image.shape[0]* image.shape[1]*image.shape[2], 1)\n",
    "    ### 代码结束 ###\n",
    "    \n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image2vector(image) = [[ 0.67826139]\n",
      " [ 0.29380381]\n",
      " [ 0.90714982]\n",
      " [ 0.52835647]\n",
      " [ 0.4215251 ]\n",
      " [ 0.45017551]\n",
      " [ 0.92814219]\n",
      " [ 0.96677647]\n",
      " [ 0.85304703]\n",
      " [ 0.52351845]\n",
      " [ 0.19981397]\n",
      " [ 0.27417313]\n",
      " [ 0.60659855]\n",
      " [ 0.00533165]\n",
      " [ 0.10820313]\n",
      " [ 0.49978937]\n",
      " [ 0.34144279]\n",
      " [ 0.94630077]]\n"
     ]
    }
   ],
   "source": [
    "# 下面给出3*3*2的array, 典型的图像时 (num_px_x, num_px_y, 3)其中的3代表RGB的值\n",
    "# 从外到内,最外层代表通道,然后时图像高度,接着时图像宽度\n",
    "image = np.array([\n",
    "       [[ 0.67826139,  0.29380381],\n",
    "        [ 0.90714982,  0.52835647],\n",
    "        [ 0.4215251 ,  0.45017551]],\n",
    "\n",
    "       [[ 0.92814219,  0.96677647],\n",
    "        [ 0.85304703,  0.52351845],\n",
    "        [ 0.19981397,  0.27417313]],\n",
    "\n",
    "       [[ 0.60659855,  0.00533165],\n",
    "        [ 0.10820313,  0.49978937],\n",
    "        [ 0.34144279,  0.94630077]]])\n",
    "\n",
    "print (\"image2vector(image) = \" + str(image2vector(image)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**期望输出**: \n",
    "\n",
    "\n",
    "<table style=\"width:100%\">\n",
    "     <tr> \n",
    "       <td> **image2vector(image)** </td> \n",
    "       <td> [[ 0.67826139]\n",
    " [ 0.29380381]\n",
    " [ 0.90714982]\n",
    " [ 0.52835647]\n",
    " [ 0.4215251 ]\n",
    " [ 0.45017551]\n",
    " [ 0.92814219]\n",
    " [ 0.96677647]\n",
    " [ 0.85304703]\n",
    " [ 0.52351845]\n",
    " [ 0.19981397]\n",
    " [ 0.27417313]\n",
    " [ 0.60659855]\n",
    " [ 0.00533165]\n",
    " [ 0.10820313]\n",
    " [ 0.49978937]\n",
    " [ 0.34144279]\n",
    " [ 0.94630077]]</td> \n",
    "     </tr>\n",
    "    \n",
    "   \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 - 正则化\n",
    "\n",
    "在机器学习和深度学习中一种常用的技术是正则化我们的数据.正则化一般会是计算结果更好,原因是在正则化之后,梯度下降会收敛得更快一些.这里正则化指的是将 x 正则化为$ \\frac {x}{\\| x \\|}$(x 的没行向量除以其范数).\n",
    "\n",
    "例如,假如 $$x= \n",
    "\\begin{bmatrix}\n",
    "    0 & 3 & 4 \\\\\n",
    "    2 & 6 & 4 \\\\\n",
    "\\end{bmatrix}\\tag{3}$$ 然后 $$\\| x\\| = np.linalg.norm(x, axis = 1, keepdims = True) = \\begin{bmatrix}\n",
    "    5 \\\\\n",
    "    \\sqrt{56} \\\\\n",
    "\\end{bmatrix}\\tag{4} $$ 并且 $$ x\\_normalized = \\frac{x}{\\| x\\|} = \\begin{bmatrix}\n",
    "    0 & \\frac{3}{5} & \\frac{4}{5} \\\\\n",
    "    \\frac{2}{\\sqrt{56}} & \\frac{6}{\\sqrt{56}} & \\frac{4}{\\sqrt{56}} \\\\\n",
    "\\end{bmatrix}\\tag{5}$$ 注意你可以对不同形状的矩阵进行除法操作并且也能成功运行:这是numpy中的广播机制,在后面的章节中会进一步介绍.\n",
    "\n",
    "**练习**:实现`normalizeRows()`来正则化矩阵的每一行.在对矩阵x应用这首函数时,x的每一行应该一个单位向量(及长度为1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 函数: normalizeRows\n",
    "\n",
    "def normalizeRows(x):\n",
    "    \"\"\"\n",
    "    实现一个函数,来正则化输入矩阵x的每一行(得到单位向量)\n",
    "    \n",
    "    参数:\n",
    "    x -- 形状为 (n, m)的numpy matrix\n",
    "    \n",
    "    返回:\n",
    "    x -- (按行)进行正则化后的numpy matrix\n",
    "    \"\"\"\n",
    "    ### 代码开始 ### (≈ 2 行代码)\n",
    "    # 计算 x_norm 作为 x 的二范数. 使用 np.linalg.norm(..., ord = 2, axis = ..., keepdims = True)\n",
    "    x_norm = np.linalg.norm(x, axis=1, ord=2, keepdims=True)\n",
    "    print(\"x_norm shape: \",x_norm.shape)\n",
    "    # x 除以其范数\n",
    "    x = x/x_norm\n",
    "    ### 代码结束 ###\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape:  (2, 3)\n",
      "x_norm shape:  (2, 1)\n",
      "normalizeRows(x) = [[ 0.          0.6         0.8       ]\n",
      " [ 0.13736056  0.82416338  0.54944226]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([\n",
    "    [0, 3, 4],\n",
    "    [1, 6, 4]])\n",
    "print(\"x shape: \",x.shape)\n",
    "print(\"normalizeRows(x) = \" + str(normalizeRows(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**期望输出**: \n",
    "\n",
    "<table style=\"width:60%\">\n",
    "\n",
    "     <tr> \n",
    "       <td> **normalizeRows(x)** </td> \n",
    "       <td> [[ 0.          0.6         0.8       ]\n",
    " [ 0.13736056  0.82416338  0.54944226]]</td> \n",
    "     </tr>\n",
    "    \n",
    "   \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**注意**:\n",
    "在`normalizeRows`中,你可以尝试输入x和x_norm的大小,观察中间结果,能够发现他们的大小并不一致.我们计算出了输入矩阵x每一行的范数,范数矩阵x_norm的行数和x的行数相当,但是只有一列.那么 x 除以 x_norm 时,为什么能够生效呢?这就是前面所讲的广播机制,我们将在这里开始讲解."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 - 广播机制和softmax函数\n",
    "\n",
    "\"广播机制(broadcasting)\"时numpy中一个重要的概念.尤其当我们处理两个不同形状的array的时候.关于广播机制的更多细节,你可以阅读器[官方文档](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**练习**:使用numpy来实现softmax函数.你可以将softmax视作一种正则化的函数,当我们的算法需要进行二分类或者更多分类的时候使用.关于softmax的更过介绍,在后面的课程中会介绍的到.\n",
    "\n",
    "**说明**:\n",
    "- $ \\text{对于 } x \\in \\mathbb{R}^{1\\times n} \\text{,     } softmax(x) = softmax(\\begin{bmatrix}\n",
    "    x_1  &&\n",
    "    x_2 &&\n",
    "    ...  &&\n",
    "    x_n  \n",
    "\\end{bmatrix}) = \\begin{bmatrix}\n",
    "     \\frac{e^{x_1}}{\\sum_{j}e^{x_j}}  &&\n",
    "    \\frac{e^{x_2}}{\\sum_{j}e^{x_j}}  &&\n",
    "    ...  &&\n",
    "    \\frac{e^{x_n}}{\\sum_{j}e^{x_j}} \n",
    "\\end{bmatrix} $ \n",
    "\n",
    "- $\\text{对于一个矩阵 } x \\in \\mathbb{R}^{m \\times n} \\text{,  $x_{ij}$ 代表 $x$ 中 $i^{th}$ 行, $j^{th}$ 列元素, 因此有: }$  $$softmax(x) = softmax\\begin{bmatrix}\n",
    "    x_{11} & x_{12} & x_{13} & \\dots  & x_{1n} \\\\\n",
    "    x_{21} & x_{22} & x_{23} & \\dots  & x_{2n} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    x_{m1} & x_{m2} & x_{m3} & \\dots  & x_{mn}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "    \\frac{e^{x_{11}}}{\\sum_{j}e^{x_{1j}}} & \\frac{e^{x_{12}}}{\\sum_{j}e^{x_{1j}}} & \\frac{e^{x_{13}}}{\\sum_{j}e^{x_{1j}}} & \\dots  & \\frac{e^{x_{1n}}}{\\sum_{j}e^{x_{1j}}} \\\\\n",
    "    \\frac{e^{x_{21}}}{\\sum_{j}e^{x_{2j}}} & \\frac{e^{x_{22}}}{\\sum_{j}e^{x_{2j}}} & \\frac{e^{x_{23}}}{\\sum_{j}e^{x_{2j}}} & \\dots  & \\frac{e^{x_{2n}}}{\\sum_{j}e^{x_{2j}}} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    \\frac{e^{x_{m1}}}{\\sum_{j}e^{x_{mj}}} & \\frac{e^{x_{m2}}}{\\sum_{j}e^{x_{mj}}} & \\frac{e^{x_{m3}}}{\\sum_{j}e^{x_{mj}}} & \\dots  & \\frac{e^{x_{mn}}}{\\sum_{j}e^{x_{mj}}}\n",
    "\\end{bmatrix} = \\begin{pmatrix}\n",
    "    softmax\\text{(first row of x)}  \\\\\n",
    "    softmax\\text{(second row of x)} \\\\\n",
    "    ...  \\\\\n",
    "    softmax\\text{(last row of x)} \\\\\n",
    "\\end{pmatrix} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 函数: softmax\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"计算输入x每一行的softmax.\n",
    "    你的代码应当无论时对于一行的向量还是大小为(n, m)的矩阵都适用.\n",
    "    \n",
    "    参数:\n",
    "    x -- 大小为(n, m)的numpy matrix\n",
    "    \n",
    "    返回:\n",
    "    s -- 大小为(n, m),x对应项进行softmax的numpy matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    ### 代码开始 ### (≈ 3 行代码)\n",
    "    # 对x中每个元素求指数.使用 np.exp(...)\n",
    "    x_exp = np.exp(x)\n",
    "    \n",
    "    # 新建一个向量x_sum , 逐行对x_exp求和. 使用 np.sum(..., axis =1, keepdims =True)\n",
    "    x_sum = np.sum(x_exp, axis=1, keepdims=True)\n",
    "    \n",
    "    # x_exp 除以 x_sum 来计算 softmax(x). numpy的广播机制自动进行.\n",
    "    s = x_exp/x_sum\n",
    "    \n",
    "    ### 代码结束 ###\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax(x) = [[  9.80897665e-01   8.94462891e-04   1.79657674e-02   1.21052389e-04\n",
      "    1.21052389e-04]\n",
      " [  8.78679856e-01   1.18916387e-01   8.01252314e-04   8.01252314e-04\n",
      "    8.01252314e-04]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([\n",
    "    [9, 2, 5, 0, 0],\n",
    "    [7, 5, 0, 0 ,0]])\n",
    "print(\"softmax(x) = \" + str(softmax(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**期望输出**:\n",
    "\n",
    "<table style=\"width:60%\">\n",
    "\n",
    "     <tr> \n",
    "       <td> **softmax(x)** </td> \n",
    "       <td> [[  9.80897665e-01   8.94462891e-04   1.79657674e-02   1.21052389e-04\n",
    "    1.21052389e-04]\n",
    " [  8.78679856e-01   1.18916387e-01   8.01252314e-04   8.01252314e-04\n",
    "    8.01252314e-04]]</td> \n",
    "     </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**注意**:\n",
    "- 假如打印 x_exp, x_sum, s的大小,你会发现x_sum的形状为 (2, 1),然而 x_exp 的形状为 (2, 5). **x_exp/x_sum** 能够运行时由于python的广播机制.\n",
    "\n",
    "恭喜你!现在你对于Python 的numpy有了较为深入的理解,并且动手实现了一些有用的函数,他们在后面的深度学习的学习中也将用到."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
